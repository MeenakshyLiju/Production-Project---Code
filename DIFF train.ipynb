{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a31b9949-f095-46f7-8555-96d7f1616f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12208/1366860589.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Marketing_Campaign'].fillna('None', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=0.007301\n",
      "Epoch 50: Loss=0.002225\n",
      "Epoch 100: Loss=0.000908\n",
      "Epoch 150: Loss=0.002202\n",
      "Epoch 200: Loss=0.001570\n",
      "Epoch 250: Loss=0.000565\n",
      "Epoch 300: Loss=0.000639\n",
      "Epoch 350: Loss=0.000818\n",
      "Epoch 400: Loss=0.000890\n",
      "Epoch 450: Loss=0.001539\n",
      "MAE: 1.6141762056007851\n",
      "MSE: 4.786164563694214\n",
      "RMSE: 2.187730459561738\n",
      "R2: 0.9881627800578641\n",
      "Model saved.\n",
      "Diffusion price predictions saved to model_output/diffusion_price_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# FINAL WORKING ONE\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Setting paths\n",
    "MODEL_DIR = os.getenv(\"SM_MODEL_DIR\", \"model_output\")\n",
    "DATA_PATH = os.getenv(\"SM_CHANNEL_TRAIN\", \"demand_forecasting_data.csv\")\n",
    "\n",
    "def safe_save(obj, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    joblib.dump(obj, path)\n",
    "\n",
    "def load_and_preprocess():\n",
    "    data = pd.read_csv(DATA_PATH)\n",
    "    data['Marketing_Campaign'].fillna('None', inplace=True)\n",
    "    \n",
    "    # Date features\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Year'] = data['Date'].dt.year\n",
    "    data['Month'] = data['Date'].dt.month\n",
    "    data['Day'] = data['Date'].dt.day\n",
    "    data['Weekday'] = data['Date'].dt.weekday\n",
    "    data.drop(columns=['Date'], inplace=True)\n",
    "    \n",
    "    # Categorical encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    cat_cols = ['Marketing_Campaign', 'Product_ID', 'Seasonal_Trend']\n",
    "    for col in cat_cols:\n",
    "        data[col] = label_encoder.fit_transform(data[col])\n",
    "    data['Public_Holiday'] = data['Public_Holiday'].astype(int)\n",
    "    \n",
    "    safe_save(label_encoder, f\"{MODEL_DIR}/diffusion_price_label_encoder.joblib\")\n",
    "    \n",
    "    # Train-test split\n",
    "    train_data = data[data['Year'] < 2021]\n",
    "    test_data = data[data['Year'] == 2021]\n",
    "    \n",
    "    # Feature selection for Price prediction\n",
    "    features = ['Year', 'Month', 'Day', 'Weekday', 'Product_ID',\n",
    "                'Marketing_Campaign', 'Seasonal_Trend', 'Stock_Availability',\n",
    "                'Base_Sales', 'Marketing_Effect', 'Seasonal_Effect',\n",
    "                'Discount', 'Competitor_Price', 'Public_Holiday', 'Demand']\n",
    "    \n",
    "    # Feature scaling\n",
    "    X_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X_train = X_scaler.fit_transform(train_data[features])\n",
    "    X_test = X_scaler.transform(test_data[features])\n",
    "    safe_save(X_scaler, f\"{MODEL_DIR}/diffusion_price_X_scaler.joblib\")\n",
    "    \n",
    "    # Target scaling for Price\n",
    "    y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    y_train = y_scaler.fit_transform(train_data['Price'].values.reshape(-1, 1))\n",
    "    y_test = test_data['Price'].values  # Keep original prices for evaluation\n",
    "    safe_save(y_scaler, f\"{MODEL_DIR}/diffusion_price_y_scaler.joblib\")\n",
    "    \n",
    "    return (X_train.astype(np.float32), X_test.astype(np.float32),\n",
    "            y_train.astype(np.float32), y_test, features)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "def train():\n",
    "    X_train, X_test, y_train, y_test, features = load_and_preprocess()\n",
    "    \n",
    "    model = DiffusionModel(input_dim=len(features))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    epochs = 500\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        permutation = np.random.permutation(len(X_train))\n",
    "        for i in range(0, len(X_train), 64):\n",
    "            indices = permutation[i:i+64]\n",
    "            batch_x, batch_y = X_train[indices], y_train[indices]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(torch.tensor(batch_x).float())\n",
    "            loss = criterion(outputs, torch.tensor(batch_y).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss={loss.item():.6f}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(torch.tensor(X_test).float()).numpy()\n",
    "        y_pred = joblib.load(f\"{MODEL_DIR}/diffusion_price_y_scaler.joblib\").inverse_transform(predictions)\n",
    "        print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "        print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "        print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(\"R2:\", r2_score(y_test, y_pred))\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'diffusion_price_model.pth'))\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "    predictions_price = y_pred.flatten()\n",
    "\n",
    "    # Create DataFrame for saving\n",
    "    df_price_preds = pd.DataFrame({\n",
    "        \"Date\": test_data[\"Date\"],\n",
    "        \"Diffusion_Predicted_Price\": predictions_price\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path_price = os.path.join(MODEL_DIR, \"diffusion_price_predictions.csv\")\n",
    "    df_price_preds.to_csv(output_path_price, index=False)\n",
    "    \n",
    "    print(f\"Diffusion price predictions saved to {output_path_price}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80796c35-5962-441c-9545-17c21c1b1ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12208/3923514343.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Marketing_Campaign'].fillna('None', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=0.000666\n",
      "Epoch 50: Loss=0.000002\n",
      "Epoch 100: Loss=0.000001\n",
      "Epoch 150: Loss=0.000001\n",
      "Epoch 200: Loss=0.000001\n",
      "Epoch 250: Loss=0.000001\n",
      "Epoch 300: Loss=0.000001\n",
      "Epoch 350: Loss=0.000001\n",
      "Epoch 400: Loss=0.000001\n",
      "Epoch 450: Loss=0.000001\n",
      "=== Evaluation Metrics (Original Demand Scale) ===\n",
      "MAE: 3494.148477572301\n",
      "MSE: 22836900.563300584\n",
      "RMSE: 4778.796978665298\n",
      "R2: 0.9841406631509436\n",
      "Model saved to model_output\n",
      "Diffusion demand predictions saved to model_output/diffusion_demand_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Setting paths again\n",
    "MODEL_DIR = os.getenv(\"SM_MODEL_DIR\", \"model_output\")\n",
    "DATA_PATH = os.getenv(\"SM_CHANNEL_TRAIN\", \"demand_forecasting_data.csv\")\n",
    "\n",
    "def safe_save(obj, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    joblib.dump(obj, path)\n",
    "\n",
    "# Load and Preprocess \n",
    "def load_and_preprocess():\n",
    "    data = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    # log transform Demand and fill NA for Marketing_Campaign\n",
    "    data['Demand'] = np.log1p(data['Demand'])\n",
    "    data['Marketing_Campaign'].fillna('None', inplace=True)\n",
    "    \n",
    "    # Date features\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Year'] = data['Date'].dt.year\n",
    "    data['Month'] = data['Date'].dt.month\n",
    "    data['Day'] = data['Date'].dt.day\n",
    "    data['Weekday'] = data['Date'].dt.weekday\n",
    "    data = data.drop(columns=['Date'])\n",
    "    \n",
    "    # Categorical encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    cat_cols = ['Marketing_Campaign', 'Product_ID', 'Seasonal_Trend']\n",
    "    for col in cat_cols:\n",
    "        data[col] = label_encoder.fit_transform(data[col])\n",
    "    data['Public_Holiday'] = data['Public_Holiday'].astype(int)\n",
    "    \n",
    "    safe_save(label_encoder, f\"{MODEL_DIR}/diffusion_label_encoder.joblib\")\n",
    "    \n",
    "    # Train-test split\n",
    "    train_data = data[data['Year'] < 2021]\n",
    "    test_data = data[data['Year'] == 2021]\n",
    "    \n",
    "    # Feature selection (for Demand model)\n",
    "    features = ['Year', 'Month', 'Day', 'Weekday', 'Product_ID',\n",
    "                'Marketing_Campaign', 'Seasonal_Trend', 'Stock_Availability',\n",
    "                'Base_Sales', 'Marketing_Effect', 'Seasonal_Effect',\n",
    "                'Discount', 'Competitor_Price', 'Public_Holiday', 'Price']\n",
    "    \n",
    "    # Use MinMaxScaler for X\n",
    "    X_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X_train = X_scaler.fit_transform(train_data[features])\n",
    "    X_test = X_scaler.transform(test_data[features])\n",
    "    safe_save(X_scaler, f\"{MODEL_DIR}/diffusion_X_scaler.joblib\")\n",
    "    \n",
    "    # Use MinMaxScaler for y \n",
    "    y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    y_train = y_scaler.fit_transform(train_data['Demand'].values.reshape(-1, 1))\n",
    "    safe_save(y_scaler, f\"{MODEL_DIR}/diffusion_y_scaler.joblib\")\n",
    "    \n",
    "    # Return test target in log-domain \n",
    "    return (X_train.astype(np.float32), \n",
    "            X_test.astype(np.float32),\n",
    "            y_train.astype(np.float32),\n",
    "            test_data['Demand'].values,  # log-domain values\n",
    "            features)\n",
    "\n",
    "# Model Architecture\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=10):\n",
    "        super().__init__()\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                m.bias.data.fill_(0.01)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.apply(init_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# Training and Evaluation\n",
    "def train():\n",
    "    X_train, X_test, y_train, y_test, features = load_and_preprocess()\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    \n",
    "    # Model setup\n",
    "    model = DiffusionModel(input_dim=X_train.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Training loop with mini-batches\n",
    "    epochs = 500\n",
    "    batch_size = 64\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(X_train_tensor.size(0))\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "            batch_x = X_train_tensor[perm[i:i+batch_size]]\n",
    "            batch_y = y_train_tensor[perm[i:i+batch_size]]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss={epoch_loss/len(X_train_tensor):.6f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Load the scaler\n",
    "        y_scaler = joblib.load(f\"{MODEL_DIR}/diffusion_y_scaler.joblib\")\n",
    "        \n",
    "        # Get predictions (they are in the scaled domain of log-transformed demand)\n",
    "        y_pred = model(X_test_tensor).numpy()\n",
    "        \n",
    "        # Inverse scale to obtain predictions in the log-domain\n",
    "        y_pred_log = y_scaler.inverse_transform(y_pred)\n",
    "        \n",
    "        # Convert predictions back to the original demand scale\n",
    "        y_pred_original = np.expm1(y_pred_log)\n",
    "        y_test_original = np.expm1(y_test)  # Since y_test is log1p-transformed\n",
    "        \n",
    "    # Compute metrics on original demand values\n",
    "    print(\"=== Evaluation Metrics (Original Demand Scale) ===\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test_original, y_pred_original))\n",
    "    print(\"MSE:\", mean_squared_error(y_test_original, y_pred_original))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_original, y_pred_original)))\n",
    "    print(\"R2:\", r2_score(y_test_original, y_pred_original))\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{MODEL_DIR}/diffusion_demand_model.pth\")\n",
    "    print(f\"Model saved to {MODEL_DIR}\")\n",
    "    \n",
    "    # Save Diffusion Demand Predictions as CSV\n",
    "    raw_data = pd.read_csv(DATA_PATH)\n",
    "    raw_data[\"Date\"] = pd.to_datetime(raw_data[\"Date\"])\n",
    "    # Select test data rows (Year == 2021)\n",
    "    test_data = raw_data[raw_data[\"Date\"].dt.year == 2021].copy()\n",
    "    \n",
    "    # The predictions are now in original demand scale; flatten the array\n",
    "    predictions_demand = y_pred_original.flatten()\n",
    "    \n",
    "    # Create DataFrame for saving\n",
    "    df_demand_preds = pd.DataFrame({\n",
    "        \"Date\": test_data[\"Date\"],\n",
    "        \"Diffusion_Predicted_Demand\": predictions_demand\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path_demand = os.path.join(MODEL_DIR, \"diffusion_demand_predictions.csv\")\n",
    "    df_demand_preds.to_csv(output_path_demand, index=False)\n",
    "    print(f\"Diffusion demand predictions saved to {output_path_demand}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
